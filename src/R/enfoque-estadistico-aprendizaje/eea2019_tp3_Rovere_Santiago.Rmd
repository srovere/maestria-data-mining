---
title: "Enfoque estadístico del aprendizaje: Trabajo Práctico nº 3"
subtitle: "Regresión logística"
author:
- Santiago Rovere (srovere@gmail.com), Facultad de Ingeniería, Universidad de Buenos Aires
date: '`r format(Sys.Date(), "%d de %B de %Y")`'
output:
  html_document:
    toc: TRUE
    toc_float: TRUE
    theme: flatly
    css: styles.css
lang: es
---

# Preparación de los datos

Se comienza el análisis propuesto cargando los paquetes necesarios, leyendo el conjunto de datos de *entrenamiento* y mostrando la estructura del mismo a fin de conocer los atributos sobre los que se van a trabajar.

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Borrar variables del ambiente
rm(list = objects())

# Carga de paquetes necesarios para hacer los gráficos
require(Cairo)
require(caret)
require(cowplot)
require(GGally)
require(ggpubr)
require(ggrepel)
require(highcharter)
require(Hmisc)
require(knitr)
require(magrittr)
require(modelr)
require(pROC)
require(tidyverse)

# Uso de Cairo para renderizar los gráficos.
options(bitmapType = "cairo")

# Cargar conjunto de datos de sobrevivientes del Titanic
datos_train <- readr::read_csv(file = "titanic_complete_train.csv")

# Mostrar estructura
head(datos_train)
```

Luego se selecciona un subconjunto de *features*, algunos de los cuales son categóricos y son transformado a *factor* de R:

  * *PassengerId*: identificador de pasajero;
  * *Survived*: Esta es la clase a predecir. Indica si el pasajero sobrevivió o no al hundimiento del Titatic
  * *Pclass*: Categoría de pasaje que compró el pasajero. Puede ser 1 (mejor categoría), 2 o 3 (peor categoría)
  * *Sex*: Sexo del pasajero
  * *Age*: Edad del pasajero
  * *SibSp*: Número de hermanos y/o cónyuge que acompañan al pasajero
  * *Parch*: Número de padres y/o hijos que acompañan al pasajero
  * *Fare*: Monto de la tarifa pagada por el pasajero
  * *Embarked*: Puerto en el cual embarcó el pasajero (C: Cherbourg, S: Southampton, Q: Queenstown)

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
datos_train %<>%
  # Seleccionar PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare y Embarked  
  dplyr::select(PassengerId, Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%
  # Transformar Survived, Pclass, Sex y Embarked a factor
  dplyr::mutate(Survived = as.factor(Survived), 
                Pclass = as.factor(Pclass),
                Sex = as.factor(Sex),
                Embarked = as.factor(Embarked))
```

A continuación se efectúa un gráfico *ggpairs* para observar las asociaciones entre variables incluyendo la clase. Lo primero que se destaca es la gran cantidad de fallecidos correspondientes a pasajeros de sexo *masculino* y que compraron pasajes de *tercera clase*. Esto indicaría que son variables con alto proder predictivo. También se observa que los pasajeros fallecidos tienen una mediana de edad un poco mayor que los sobrevivientes. Por último, también se observa que hay una cantidad levemente mayor de sobrevivientes de pasajeros que pagaron tarifas más altas.

```{r, echo=TRUE, warnings=FALSE, message=FALSE, fig.width=8, fig.height=10 }
GGally::ggpairs(data = datos_train,
                mapping = ggplot2::aes(col = Survived),
                columns = which(colnames(datos_train) %in% 
                                  c("Pclass", "Sex", "Age", "Fare"))) +
  ggplot2::theme_bw() +
  ggplot2::theme(
    legend.position = 'bottom',
    axis.text.x = element_text(angle = 90, hjust = 1)
  ) 
```

Para finalizar la etapa de preparación de los datos, tomamos el conjunto de datos de entrenamiento y separamos 70% de las observaciones para *entrenamiento* y el 30% restante con fines de *validación*. El gráfico interactivo de barras que se muestra a continuación fue confeccionado para corroborar que se mantenga la proporción de clases a predecir en los conjuntos de datos resultantes. Pueden visualizarse los porcentajes de cada clase deslizando el puntero del mouse sobre cada una de las barras.

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Dividir el conjunto de entrenamiento en 70% para entrenamiento y 30% para validacion.
# Se define una semilla para que el ejemplo sea reproducible.
set.seed(0)
entrenamiento_validacion <- datos_train %>% 
  modelr::resample_partition(c(train = 0.7, test = 0.3))
datos_entrenamiento <- entrenamiento_validacion$train %>%
  as_tibble()
datos_validacion <- entrenamiento_validacion$test %>% 
  as_tibble()

# Analizar distribución de clase para verificar que se preserven las proporciones
datos.grafico.proporcion.clase <- dplyr::bind_rows(
  datos_train %>% dplyr::mutate(Conjunto = "Original de entrenamiento"),
  datos_entrenamiento %>% dplyr::mutate(Conjunto = "Entrenamiento (70%)"),
  datos_validacion %>% dplyr::mutate(Conjunto = "Validación (30%)")) %>%
  dplyr::mutate(Survived = dplyr::case_when(Survived == 0 ~ "No sobrevivió",
                                            TRUE ~ "Sobrevivió"),
                Conjunto = factor(Conjunto, 
                                  levels = c("Original de entrenamiento", "Entrenamiento (70%)", "Validación (30%)"))) %>%
  dplyr::group_by(Conjunto) %>%
  dplyr::mutate(Total = dplyr::n()) %>%
  dplyr::group_by(Conjunto, Survived, Total) %>%
  dplyr::summarise(Cantidad = dplyr::n()) %>%
  dplyr::mutate(Porcentaje = 100 * Cantidad / Total)
  
suppressWarnings(highcharter::highchart() %>%
  highcharter::hc_add_series(data = datos.grafico.proporcion.clase, type = "column",
                             mapping = highcharter::hcaes(x = Conjunto, y = Porcentaje, group = Survived)) %>%
  highcharter::hc_colors(c("#e31a1c", "#1f78b4")) %>%
  highcharter::hc_xAxis(title = list(text = "Conjunto de datos"), type = "category", 
                        categories = unique(datos.grafico.proporcion.clase$Conjunto)) %>%
  highcharter::hc_yAxis(title = list(text = "Porcentaje de datos en la clase"), 
                        min = 0, max = 100) %>%
  highcharter::hc_tooltip(valueDecimals = 2, valueSuffix = ' %') %>%
  highcharter::hc_title(text = "Distribución de clases por conjunto de datos"))
```

# Predicciones 

Se realiza un primer modelo de regresión logística de acuerdo a los atributos propuestos: *Pclass*, *Sex* y *Age*. A continuación se presentan los coeficientes de cada una de las covariables. Para el caso de las variables categóricas *Pclass* y *Sex* se consideraron como categorías basales las correspondientes a *primera clase* y *sexo femenino* respectivamente.

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Se realiza el primer modelo con las variables Pclass, Sex y Age
modelo.1 <- glm(formula = Survived ~ Pclass + Sex + Age, 
                family = 'binomial', data = datos_entrenamiento)
knitr::kable(
  broom::tidy(modelo.1)
)
```

De la tabla anterior observamos que todos los coeficientes de las covariables propuestas son negativos y altamente significativos. Que un coeficiente sea negativo, indica que un incremento en el valor de la covariable disminuye la probabilidad de supervivencia esperada del pasajero *ceteris paribus*. Para el caso de la edad, esto es consistente con el análisis previo, donde se había observado que la edad de los fallecidos tenía una mediana mayor que la de los sobrevivientes.

Para el caso de las variables categórias, se observa que ser de sexo masculino disminuye la probabilidad esperada de supervivencia. Lo mismo sucede cuando *empeora* la categoría en la que viaja del pasajero. Es decir, los de segunda categoría tienen menos probabilidad esperada de superviviencia que los de primera y lo mismo ocurre con los de tercera respecto de los de segunda. Hasta aquí todos los hallazgos han sido consistentes con lo observado en el gráfico de *ggpairs*.

Finalmente, y a modo de ejemplo, se muestra la probabilidad esperada de supervivencia para dos pasajeros con las siguientes características:

  * *Rose*: mujer de 17 años que viaja en primera clase
  * *Jack*: hombre de 20 años que viaja en tercera clase

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Ahora se reponde a la pregunta: Quien tiene mas chances de sobrevivir?
data.rose <- data.frame(Nombre = "Rose",
                        Pclass = factor(1, levels = levels(datos_entrenamiento$Pclass)), 
                        Sex = factor("female", levels = levels(datos_entrenamiento$Sex)),
                        Age = 17)
prob.rose <- predict(object = modelo.1, newdata = data.rose, type = "response")

data.jack <- data.frame(Nombre = "Jack",
                        Pclass = factor(3, levels = levels(datos_entrenamiento$Pclass)), 
                        Sex = factor("male", levels = levels(datos_entrenamiento$Sex)),
                        Age = 20)
prob.jack <- predict(object = modelo.1, newdata = data.jack, type = "response")

knitr::kable(
  rbind(dplyr::mutate(data.rose, Prob = prob.rose), dplyr::mutate(data.jack, Prob = prob.jack)),
  digits = 3, col.names = c("Pasajero", "Clase", "Sexo", "Edad", "Prob. esperada de sobrevivir")
)
```

Se observa que la probabilidad de supervivencia esperada de Rose es prácticamente 10 veces mayor que la de Jack, lo cual es esperable debido principalmente a las diferencias de sexo y clase en la que viajan ambos.

# Generación de modelos

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Se defines las formulas para los 3 modelos a analizar
formulas.modelos <- modelr::formulas(.response = ~Survived,
                                     sexo_tarifa_edad = ~Sex + Fare + Age,
                                     tarifa_lugar = ~Fare + Embarked,
                                     sexo_clase_lugar_edad = ~ Sex + Pclass + Embarked + Age)

# Generar modelos en base a las formulas
modelos <- dplyr::tibble(formulas.modelos) %>% 
  # Generar features con el modelo y la expresion del mismo
  dplyr::mutate(Expresion = paste(formulas.modelos),
                Nombre = names(formulas.modelos),
                Modelo = purrr::map(formulas.modelos, ~glm(.,family = 'binomial', data = datos_entrenamiento))) %>%
  # Seleccionar Expresion y Modelo
  dplyr::select(Expresion, Nombre, Modelo) %>%
  # Agregar modelo inicial
  dplyr::bind_rows(tibble::tibble(Expresion = "Survived ~ Pclass + Sex + Age", Modelo = list(modelo.1)))

# Mostrar los modelos ordenados por el deviance de cada uno de ellos
modelos %>% 
  dplyr::mutate(glance = purrr::map(Modelo, broom::glance)) %>%
  tidyr::unnest(glance) %>%
  dplyr::select(Expresion, deviance, null.deviance, logLik, AIC, BIC) %>%
  dplyr::arrange(deviance)
```

# Evaluación del modelo

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Generamos la curva ROC y calculamos ROC AUC para el modelo elegido (sexo_clase_lugar_edad)
prediccion.mejor.modelo <- modelos %>% 
  dplyr::filter(Nombre == "sexo_clase_lugar_edad") %>% 
  dplyr::mutate(pred = purrr::map(Modelo, broom::augment, type.predict = "response")) %>%
  tidyr::unnest(pred)

# Calcular ROC
roc.mejor.modelo <- pROC::roc(response = prediccion.mejor.modelo$Survived, predictor = prediccion.mejor.modelo$.fitted)
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Graficar ROC
pROC::ggroc(roc.mejor.modelo, size = 1, legacy.axes = TRUE) + 
  ggplot2::geom_abline(slope = 1, intercept = 0, linetype = 'dashed') + 
  ggplot2::geom_label(data = data.frame(x = 0.9, y = 0.1),
                      mapping = ggplot2::aes(x = x, y = y, label = sprintf("AUC: %.3f", roc.mejor.modelo$auc))) +
  ggplot2::labs(title = 'Curva ROC', subtitle = 'Modelo basado en sexo, clase, lugar de embarcación y edad',
                y = 'Tasa de verdaderos positivos (TPR)', x = "Tasa de falsos positivos (FPR)") +
  ggplot2::theme_bw() +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5),
    plot.subtitle = ggplot2::element_text(hjust = 0.5)
  )
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Violing plot
ggplot2::ggplot(data = prediccion.mejor.modelo, 
                mapping = ggplot2::aes(x = Survived, y = .fitted, group = Survived, fill = Survived)) + 
  ggplot2::geom_violin() +
  ggplot2::scale_fill_manual(values = c("0" = "tomato", "1" = "darkslategray4"),
                             labels = c("0" = "No sobrevivió", "1" = "Sobrevivió"), name = "") +
  ggplot2::labs(title = 'Gráfico de violín', subtitle = 'Modelo basado en sexo, clase, lugar de embarcación y edad', 
                y = 'Probabilidad predicha', x = "") +
  ggplot2::theme_bw() + 
  ggplot2::theme(
    legend.position = 'bottom',
    plot.title = ggplot2::element_text(hjust = 0.5),
    plot.subtitle = ggplot2::element_text(hjust = 0.5),
    axis.ticks.x = ggplot2::element_blank(),
    axis.text.x = ggplot2::element_blank()
  )
```

# Elección del punto de corte

```{r, echo=TRUE, warnings=FALSE, message=FALSE, fig.width=8 }
# Prediccion utilizando conjunto de validacion
prediccion.validacion <- modelos %>% 
  dplyr::filter(Nombre == "sexo_clase_lugar_edad") %>% 
  dplyr::mutate(pred = purrr::map(Modelo, predict, newdata = dplyr::select(datos_validacion, -Survived), 
                                  type = "response")) %>%
  tidyr::unnest(pred) %>%
  dplyr::pull(pred)
clases.validacion <- datos_validacion %>%
  dplyr::mutate(Clase = as.integer(as.character(Survived))) %>%
  dplyr::pull(Clase)

# Definir metricas de prediccion en funcion de un umbral de corte
MetricasPrediccion <- function(probabilidades, clase, umbral.corte) {
  predicciones     <- ifelse(probabilidades > umbral.corte, 1, 0)
  matriz.confusion <- caret::confusionMatrix(
    table(as.character(predicciones), as.character(clase)), 
  positive = "1")
  
  broom::tidy(matriz.confusion) %>%
    dplyr::select(term, estimate) %>%
    dplyr::filter(term %in% c('accuracy', 'recall', 'specificity', 'precision')) %>%
    dplyr::mutate(umbral = umbral.corte)
}

# Calcular metricas en funcion del umbral
puntos.corte  <- list(p1 = 0, p2 = 0)
distancias    <- list(p1 = 1, p2 = 1)
metricas      <- purrr::map_dfr(
  .x = seq(from = 0.03, to = 0.96, by = 0.001),
  .f = function(umbral.corte) {
    metricas.umbral    <- MetricasPrediccion(prediccion.validacion, clases.validacion, 
                                             umbral.corte = umbral.corte)
    recall.umbral      <- dplyr::filter(metricas.umbral, term == "recall") %>% 
      dplyr::pull(estimate)
    precision.umbral   <- dplyr::filter(metricas.umbral, term == "precision") %>% 
      dplyr::pull(estimate)
    accuracy.umbral    <- dplyr::filter(metricas.umbral, term == "accuracy") %>% 
      dplyr::pull(estimate)
    distancia.prec.rec <- abs(recall.umbral - precision.umbral)
    distancia.acc.rec  <- abs(recall.umbral - accuracy.umbral)
    if (distancia.prec.rec < distancias$p1) {
      puntos.corte$p1 <<- umbral.corte
      distancias$p1   <<- distancia.prec.rec
    }
    if (distancia.acc.rec < distancias$p2) {
      puntos.corte$p2 <<- umbral.corte
      distancias$p2   <<- distancia.acc.rec
    }
    return (metricas.umbral)
  }
)

# Graficamos metricas en funcion del umbral
ggplot2::ggplot(data = metricas) + 
  ggplot2::geom_line(mapping = ggplot2::aes(x = umbral, y = estimate, group = term, color = term), size = 0.7) +
  ggplot2::geom_vline(xintercept = puntos.corte$p1, linetype = "dotted") +
  ggplot2::geom_vline(xintercept = puntos.corte$p2, linetype = "dotted") +
  ggrepel::geom_label_repel(data = data.frame(x = puntos.corte$p1, y = 0), 
                            mapping = ggplot2::aes(x = x, y = y, label = sprintf("P1 = %.3f", x)), 
                            colour = 'black', nudge_x = 0.1, nudge_y = 0.1) +
  ggrepel::geom_label_repel(data = data.frame(x = puntos.corte$p2, y = 0), 
                            mapping = ggplot2::aes(x = x, y = y, label = sprintf("P2 = %.3f", x)), 
                            colour = 'black', nudge_x = -0.1, nudge_y = 0.1) +
  ggplot2::labs(title = 'Accuracy, Sensitivity (o Recall), Specificity y Precision', 
                subtitle = 'Modelo basado en sexo, clase, lugar de embarcación y edad', 
                col = "Métrica", x = "Punto de corte", y = "Valor de la métrica") +
  ggplot2::theme_bw() +
  ggplot2::theme(
    legend.position = 'bottom',
    plot.title = ggplot2::element_text(hjust = 0.5),
    plot.subtitle = ggplot2::element_text(hjust = 0.5)
  )
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# MdC para primer punto de corte
predicciones.1     <- ifelse(prediccion.validacion > puntos.corte$p1, 1, 0)
matriz.confusion.1 <- caret::confusionMatrix(
  table(as.character(predicciones.1), as.character(clases.validacion), dnn = c("predicciones", "observaciones")), 
  positive = "1")$table
rownames(matriz.confusion.1) <- c("Fallecidos predichos", "Sobrevivientes predichos")
colnames(matriz.confusion.1) <- c("Fallecidos reales", "Sobrevivientes reales")

# MdC para segundo punto de corte
predicciones.2     <- ifelse(prediccion.validacion > puntos.corte$p2, 1, 0)
matriz.confusion.2 <- caret::confusionMatrix(
  table(as.character(predicciones.2), as.character(clases.validacion), dnn = c("predicciones", "observaciones")), 
  positive = "1")$table
rownames(matriz.confusion.2) <- c("Fallecidos predichos", "Sobrevivientes predichos")
colnames(matriz.confusion.2) <- c("Fallecidos reales", "Sobrevivientes reales")
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
knitr::kable(matriz.confusion.1) 
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
knitr::kable(matriz.confusion.2)
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
comparacion.metricas.validacion <- MetricasPrediccion(prediccion.validacion, clases.validacion, puntos.corte$p1) %>%
  dplyr::bind_rows(MetricasPrediccion(prediccion.validacion, clases.validacion, puntos.corte$p2)) %>%
  tidyr::pivot_wider(names_from = "term", values_from = "estimate") %>%
  dplyr::rename("Punto de corte" = umbral, Accuracy = accuracy, Recall = recall, Precision = precision, Specificity = specificity)
knitr::kable(comparacion.metricas.validacion, digits = 3)
```

# Dataset de testeo

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
# Cargar conjunto de datos de test y aplicar las mismas transformaciones que para train
datos_test <- readr::read_csv(file = "titanic_complete_test.csv") %>%
  # Seleccionar las variables PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare y Embarked  
  dplyr::select(PassengerId, Survived, Pclass, Sex, Age, SibSp,Parch, Fare, Embarked) %>%
  # Transformar las variables Survived, Pclass, Sex y Embarked a factor
  dplyr::mutate(Survived = as.factor(Survived), 
                Pclass = as.factor(Pclass),
                Sex = as.factor(Sex),
                Embarked = as.factor(Embarked))

# Aplicar el modelo a conjunto de test
prediccion.test <- modelos %>% 
  dplyr::filter(Nombre == "sexo_clase_lugar_edad") %>% 
  dplyr::mutate(pred = purrr::map(Modelo, predict, newdata = dplyr::select(datos_test, -Survived), 
                                  type = "response")) %>%
  tidyr::unnest(pred) %>%
  dplyr::pull(pred)
clases.test <- datos_test %>%
  dplyr::mutate(Clase = as.integer(as.character(Survived))) %>%
  dplyr::pull(Clase)

# Realizar predicciones en base a mejor al punto de corte P2
predicciones.3     <- ifelse(prediccion.test > puntos.corte$p1, 1, 0)
matriz.confusion.3 <- caret::confusionMatrix(
  table(as.character(predicciones.3), as.character(clases.test), dnn = c("predicciones", "observaciones")), 
  positive = "1")$table
rownames(matriz.confusion.3) <- c("Fallecidos predichos", "Sobrevivientes predichos")
colnames(matriz.confusion.3) <- c("Fallecidos reales", "Sobrevivientes reales")
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
knitr::kable(matriz.confusion.3)
```

```{r, echo=TRUE, warnings=FALSE, message=FALSE }
comparacion.metricas.test <- MetricasPrediccion(prediccion.test, clases.test, puntos.corte$p1) %>%
  dplyr::bind_rows(MetricasPrediccion(prediccion.test, clases.test, puntos.corte$p2)) %>%
  tidyr::pivot_wider(names_from = "term", values_from = "estimate") %>%
  dplyr::rename("Punto de corte" = umbral, Accuracy = accuracy, Recall = recall, Precision = precision, Specificity = specificity)
knitr::kable(comparacion.metricas.test, digits = 3)
```
