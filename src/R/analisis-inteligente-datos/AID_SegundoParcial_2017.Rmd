---
title: "Segundo examen parcial"
subtitle: "Análisis Inteligente de Datos (2017)"
author:
  - Santiago Luis Rovere (srovere@gmail.com)
date: '`r format(Sys.Date(), "%d de %B de %Y")`'
output:
  html_document:
    toc: true
    number_sections: yes
  pdf_document:
    number_sections: yes
  html_notebook:
    number_sections: yes
---

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# Inicializacion de ambiente
rm(list = objects())
require(ADGofTest)
require(biotools)
require(Cairo)
require(car)
require(dplyr)
require(ggplot2)
require(Hotelling)
require(MASS)
require(NbClust)
require(plotly)
require(readr)
require(readxl)
require(tidyr)
options(bitmapType = "cairo")

# Inicializamos la semilla en 0
set.seed(0)
```

# Clustering

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# Carga de datos
indicadores <- readr::read_delim(file = "Indicadores.csv", delim = "\t") %>%
  as.data.frame()
rownames(indicadores) <- indicadores$Pais
indicadores <- as.matrix(dplyr::select(indicadores, -Pais))
```

## Clustering jerárquico

Primero hacemos un PCA para reducir la dimensionalidad y encontrar factores ocultos o variables latentes.

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# PCA
pca            <- stats::princomp(x = indicadores, cor = TRUE)
prop.varianzas <- (pca$sdev ^ 2) / sum((pca$sdev ^ 2))

ggplot(data = data.frame(proporcion = 100 * cumsum(prop.varianzas), componente = 1:length(prop.varianzas)),
       mapping = ggplot2::aes(x = componente, y = proporcion, fill = componente)) +
  ggplot2::scale_x_continuous(breaks = 1:length(prop.varianzas)) +
  ggplot2::geom_bar(stat = 'identity') +
  ggplot2::geom_text(mapping = ggplot2::aes(y = proporcion + 1, label = sprintf("%0.2f", proporcion))) +
  ggplot2::labs(x = "Componente", y = "Porcentaje acumulado de varianza explicada") +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = 'none')
```

Seleccionamos las primeras 3 componentes que explican más del 82% de la varianza. Los loadings de cada una de ellas están representadas en el siguiente gráfico. En todos los casos son componentes de forma.

```{r, echo=FALSE, warnings=FALSE, message=FALSE, fig.width=10, fig.height=10 }
scores         <- pca$scores[, 1:3]
loadings       <- pca$loadings[, 1:3] 
loadings.largo <- data.frame(loadings) %>%
  dplyr::mutate(Variable = rownames(.)) %>%
  tidyr::gather(key = Componente, value = Loading, -Variable)
ggplot(data = loadings.largo, mapping = ggplot2::aes(x = Variable, y = Loading, fill = Loading)) +
  ggplot2::geom_bar(stat = 'identity') +
  ggplot2::facet_wrap(~Componente, ncol = 1) +
  ggplot2::scale_fill_distiller(type = "div", palette = "RdBu", direction = 1) +
  ggplot2::labs(x = "Variable", y = "Loading") +
  ggplot2::theme_bw() +
  ggplot2::theme(
    legend.position = 'none',
    axis.text.x = ggplot2::element_text(angle = 90)
  )
```

Con esta 3 componentes nos disponemos a realizar un clustering jerárquico ascendente (aglomerativo) utilizando como métrica de distancia *ward.D2* (es una mejora introducida al método de Ward original (1963) por Murtagh y Legendre (2014). Seleccionamos 4 grupos.

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
matriz.distancias  <- stats::dist(x = scores, method = "euclidean")
cluster.jerarquico <- stats::hclust(d = matriz.distancias, method = "ward.D2")
plot(cluster.jerarquico, main = "Clasificación de países", xlab = "País", ylab = "Distancia")
grupos             <- stats::rect.hclust(cluster.jerarquico, k = 4, border = "red")
scores.df          <- as.data.frame(scores) %>%
  dplyr::mutate(pais = rownames(.))
scores.grupos.jer  <- purrr::map_dfr(
  .x = seq_len(length(grupos)),
  .f = function(seq_index) {
    filas        <- grupos[[seq_index]]
    scores.grupo <- scores.df[filas,] %>%
      dplyr::mutate(grupo = seq_index)
    return (scores.grupo)
  }
)
```

Ahora graficamos el cluster resultante en coordenadas de las primeras 3 componentes principales.

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
plotly::plot_ly(data = scores.grupos.jer, x = ~Comp.1, y = ~Comp.2, z = ~Comp.3, mode = "markers",
                color = ~grupo, colors = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Comp. 1'),
                      yaxis = list(title = 'Comp. 2'),
                      zaxis = list(title = 'Comp. 3')),
         title = "Clustering jerárquico")
```

## Cluster no jerárquico

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
cluster.kmeans   <- stats::kmeans(x = scores, centers = 4, iter.max = 100)
scores.grupos.km <- scores.df %>%
  dplyr::mutate(grupo = cluster.kmeans$cluster)
plotly::plot_ly(data = scores.grupos.km, x = ~Comp.1, y = ~Comp.2, z = ~Comp.3, mode = "markers",
                color = ~grupo, colors = c('#e41a1c', '#377eb8', '#4daf4a', '#984ea3')) %>%
  add_markers() %>%
  layout(scene = list(xaxis = list(title = 'Comp. 1'),
                      yaxis = list(title = 'Comp. 2'),
                      zaxis = list(title = 'Comp. 3')),
         title = "Clustering con K-means")
```

## Selección de la cantidad de clusters
```{r, echo=FALSE, warnings=FALSE, message=FALSE }
metricas <- purrr::map_dfr(
  .x = seq(from = 2, to = 15),
  .f = function(k) {
    cluster.kmeans.k  <- stats::kmeans(x = scores, centers = k, iter.max = 100)
    cluster.kmeans.k1 <- stats::kmeans(x = scores, centers = k+1, iter.max = 100)
    BSS.k             <- cluster.kmeans.k$betweenss
    WSS.k             <- cluster.kmeans.k$tot.withinss
    WSS.k1            <- cluster.kmeans.k1$tot.withinss
    F.k.k1            <- (WSS.k - WSS.k1) / (WSS.k1 / (nrow(scores) - k - 1))
    F.comparacion     <- stats::qf(0.95, ncol(scores), ncol(scores)*(nrow(scores)-k-1))
    return (data.frame(k = k, WSS = WSS.k, BSS = BSS.k, F.k.k1 = F.k.k1, F.comparacion = F.comparacion, stringsAsFactors = FALSE) %>%
              dplyr::mutate(Aumentar = F.k.k1 > F.comparacion, WSS.BSS.rate = WSS/BSS)) 
  }
)
ggplot2::ggplot(data = metricas) +
  ggplot2::geom_line(mapping = ggplot2::aes(x = k, y = WSS)) +
  ggplot2::geom_vline(xintercept = 4, linetype = "dotted") +
  ggplot2::labs(x = "Cantidad de clusters", y = "Valor", col = "Métrica",
                title = "Métricas para distintos números de clusters",
                subtitle = "Comparación de WSS para distintos valores de k") +
  ggplot2::theme_bw() +
  ggplot2::theme(
    legend.position = 'bottom'
  )

# Uso de NbClust para determinar el mejor valor de "k".
invisible({
  pdf(file = NULL)
  resultados.k <- suppressWarnings(suppressMessages(NbClust::NbClust(data = scores, method = "kmeans", index = "all")))
  dev.off()
})
```

# Comparación de medias multivariadas de dos poblaciones

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# Carga de datos. Pasamos el sexo a factor y luego a numero para convertirlo a numerico
empleados <- readr::read_delim(file = "empleados.csv", delim = ";") %>%
  dplyr::select(-ID) %>%
  dplyr::mutate(sexo = as.integer(as.factor(sexo))) 
```

## Test a realizar

Se tienen 2 poblaciones, cada una de las cuales tiene asociadas 7 variables. Se desea probar si las medias de ambas poblaciones son iguales o no. Para ello, se plantea el test de Hotelling para comparación de medias multivariadas en 2 poblaciones diferentes. Sean $\mu$<sub>1</sub> y $\mu$<sub>2</sub> las medias para cada población, el test a llevar a cabo tiene las siguientes hipótesis:

  * H<sub>0</sub>: $\mu$<sub>1</sub> = $\mu$<sub>2</sub>
  * H<sub>1</sub>: $\mu$<sub>1</sub> != $\mu$<sub>2</sub>
  
## Realización del test

```{r, echo=FALSE, warnings=FALSE, message=TRUE }
print(Hotelling::hotelling.test(x = .~ minoria, data = empleados))
```

Se rechaza la hipótesis nula con un *p-valor* significativamente bajo, por lo que podemos afirmar que cada grupo tiene media distinta. Procedemos entonces a clasificar cada grupo haciendo análisis discriminante. Verificamos normalidad multivariada (test de Shapiro-Wilk multivariado) y homocedasticidad (test M de Box).

```{r, echo=FALSE, warnings=FALSE, message=TRUE }
# Normalidad multivariadad por grupos
for (grupo in unique(empleados$minoria)) {
  cat(paste0("Analizando normalidad para grupo ", grupo))
  matriz.datos <- empleados %>%
    dplyr::filter(minoria == grupo) %>%
    dplyr::select(-minoria) %>%
    as.matrix()
  print(mvnormtest::mshapiro.test(t(matriz.datos)))
}

# Homocedasticidad
biotools::boxM(data = as.matrix(dplyr::select(empleados, -minoria)), 
     grouping = as.matrix(dplyr::select(empleados, minoria)))
```

Como se observa, no se satisface la normalidad para ninguno de los dos grupos. Tampoco la condición de homocedasticidad. El discrimiante cuadrático se aplica cuando hay condición de normalidad multivariante, pero no de homocedasticidad. Sin embargo, también es robusto a la ausencia de normalidad multivariante. Por tal motivo aplicamos dicho método.

## QDA

Analizamos primero el poder de predicción con el método *ingenuo* (evaluar la clasificación con el mismo conjunto de datos de entrenamiento).

```{r, echo=FALSE, warnings=FALSE, message=TRUE }
modelo.qda <- MASS::qda(minoria ~ ., data = empleados, CV = FALSE)
prediccion <- stats::predict(modelo.qda, dplyr::select(empleados, -minoria))
print("Matriz de contingencia")
table(prediccion$class, empleados$minoria)
sprintf("Clasifica correctamente el %.2f%% de los casos", 100 * mean(prediccion$class == empleados$minoria))
```

Ahora realizamos *cross-validation* excluyendo 20% de los datos para validación.

```{r, echo=FALSE, warnings=FALSE, message=TRUE }
set.seed(0) # Fijo la semilla para que todos obtengamos los mismos resultados
filas.validacion       <- sample.int(n = nrow(empleados), size = 0.2 * nrow(empleados))
conjunto.entrenamiento <- empleados[-filas.validacion, ]
conjunto.validacion    <- empleados[filas.validacion, ]
qda.entrenamiento      <- MASS::qda(x = dplyr::select(conjunto.entrenamiento, -minoria), grouping = conjunto.entrenamiento$minoria)
qda.validacion         <- stats::predict(qda.entrenamiento, dplyr::select(conjunto.validacion, -minoria))

print("Matriz de contingencia")
table(qda.validacion$class, conjunto.validacion$minoria)
sprintf("Clasifica correstamente el %.2f%% de los casos", 100 * mean(qda.validacion$class == conjunto.validacion$minoria))
```

Para evitar seleccionar un conjunto de validación que sea "bueno" o "malo", se debería hacer *k-fold cross validation* a fin de realizar múltiples entrenamientos y validaciones. Luego, se debería promediar el *accuracy* obtenido para cada *fold*.

## Excluimos el último individuo, re-entrenamos y predecimos su clase.

```{r, echo=FALSE, warnings=FALSE, message=TRUE }
conjunto.entrenamiento <- empleados[-nrow(empleados), ]
conjunto.validacion    <- empleados[nrow(empleados), ]
qda.entrenamiento      <- MASS::qda(x = dplyr::select(conjunto.entrenamiento, -minoria), grouping = conjunto.entrenamiento$minoria)
qda.validacion         <- stats::predict(qda.entrenamiento, dplyr::select(conjunto.validacion, -minoria))

print(paste0("Clasificación real: ", conjunto.validacion$minoria, ". Clasficiación con QDA: ", qda.validacion$class))
```

# ANOVA

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# Carga de datos.
presion <- readxl::read_excel(path = "presion.xlsx") %>%
  tidyr::gather(key = tratamiento, value = presion)
```

## Modelo

Se tienen 5 poblaciones, cada una de las cuales tiene recibe un tratamiento para la hipertensión. Sea $\mu$<sub>i</sub> la media de la presión sistólica medida para la población <sub>i</sub>. Se desea probar si las medias de todas poblaciones son iguales o no. Para ello, se realiza una ANOVA, con las siguientes hipótesis:

  * H<sub>0</sub>: $\mu$<sub>1</sub> = $\mu$<sub>2</sub> = ... = $\mu$<sub>5</sub>
  * H<sub>1</sub>: $\exists$ (i, j) / $\mu$<sub>i</sub> != $\mu$<sub>j</sub>
  
## Prueba y validación de supuestos

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
# Carga de datos.
aov.presion <- stats::aov(presion~tratamiento, data = presion)
residuos    <- stats::residuals(aov.presion)

cat("Test de normalidad (Shapiro-Wilk) de los residuos")
stats::shapiro.test(residuos)

cat("Test de homocedasticidad (Levene)")
leveneTest(presion~tratamiento, data = presion)
```

## Conclusiones

Dado que se cumplen las condiciones de normalidad y homocedasticidad, podemos concluir en base a los resultados de la ANOVA:

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
summary(aov.presion)
```

Dado que el *p-valor* es muy pequeño, podemos afirmar que existen diferencias estadísticamente siginificativas como para rechazar la igualdad de medias. Finalmente, realizamos el test de Tukey para encontrar mayor información:

```{r, echo=FALSE, warnings=FALSE, message=FALSE }
stats::TukeyHSD(aov.presion, conf.level=0.95)
```

Vemos por ejemplo que hay diferencias significativas entre los grupos *dosis alta/dieta hiposódica* y *dosis media/dieta hiposódica*. En ambos casos hay evidencia de que la media de los grupos a los que les suministró dosis en cantidades media o alta es **menor** que la de aquellos que solamente hicieron dieta. 

En menor medida, hay diferencias (aunque no tan significativas como las anteriores) entre *dieta+dosis baja/dieta hiposódica*, *dosis baja/dieta hiposódica hiposódica*, *dosis alta/dosis baja* y *dosis media/dieta+dosis baja*. En todos los casos, los primeros grupos parecen tener medias *menores* que los últimos.

No se detectan diferencias significativas entre los grupos *dosis alta/dosis media*, *dosis media/dosis baja*, *dosis media/dieta+dosis baja* y *dosis baja/dieta+dosis baja*. En estos casos se podría llegar a decir que las medias para cada combinación de par de grupos es similar.

## Uso de transformaciones

Se podría haber utilizado transformaciones de Box-Cox para el caso de que no se cumpliera alguno de los supuestos (normalidad y homocedasticidad) o ambos. en este caso, se elige el valor de $\lambda$ que maximiza la función de verosimilitud. A continuación se aplica la siguiente transformación:

Y = X <sup>$\lambda$</sup>

Con esta nueva variable Y sea realiza el test de ANOVA y se analizan los supuestos. Si los supuestos se cumplen, entonces es posible concluir a partir de los resultados de la ANOVA. De no ser así, se puede hacer un test no paramétrico como el de Kruskal-Wallis.